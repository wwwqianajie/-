# -大数据平台构建（Hadoop生态系统）
搭建Hadoop集群，使用HDFS、MapReduce、Spark、Hive、Hbase等
数据清洗与分析
使用Spark进行数据清洗分析，去除异常值、重复值，计算各种统计指标、

分析数据的分布等
模型建立与评估
数据获取：使用Java API连接Hbase等数据库

数据处理与特征提取：使用Spark内置函数将数据转换为适合建模的形式。

对数据进行必要的处理，如数据清洗、编码转换等

模型构建：在数据准备完成后，开始构建模型。例如逻辑回归模型，并对其

进行训练
参数优化与调整
模型评估：使用 些评估指标来衡量模型的性能，如准确率、召回率、

F1分数等

参数优化：使用网格搜索等方法来优化模型的参数
数据可视化
后端数据调用：后端使用Spring Boot框架，结合已经封装好的Spark读写
Hbase的类

前端数据展示：前端使用Thymeleaf模板引擎，结合Echarts等前端图表库，
后端获取数据以直观的图表形式展示给用户
